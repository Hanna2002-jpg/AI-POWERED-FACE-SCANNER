# Face Recognition System Configuration
# =====================================

# Model Configuration
model:
  architecture: "arcface"        # Options: arcface, insightface, facenet
  backbone: "resnet50"           # Options: resnet50, resnet101, efficientnet-b0
  embedding_size: 512            # Embedding dimension
  pretrained: true               # Use pre-trained backbone
  dropout_rate: 0.1             # Dropout rate for regularization

# Training Configuration
training:
  batch_size: 32                # Batch size for training
  learning_rate: 0.001          # Initial learning rate
  epochs: 20                    # Number of training epochs
  optimizer: "adam"             # Options: adam, sgd, adamw
  scheduler: "steplr"           # Options: steplr, cosine, plateau
  weight_decay: 1e-4            # L2 regularization strength
  gradient_clip: 1.0            # Gradient clipping value
  
  # Fine-tuning Strategy
  freeze_backbone: false        # Whether to freeze backbone initially
  unfreeze_after_epoch: 5       # Epoch to unfreeze backbone (if frozen)
  
  # Data Augmentation
  use_augmentation: true        # Enable data augmentation
  augmentation_strength: 0.5    # Augmentation intensity (0-1)
  
  # Early Stopping
  patience: 5                   # Early stopping patience
  min_delta: 0.001             # Minimum improvement threshold

# Data Configuration
data:
  train_split: 0.7              # Training set ratio
  test_split: 0.3               # Test set ratio
  image_size: [224, 224]        # Input image dimensions
  normalize_mean: [0.485, 0.456, 0.406]  # ImageNet normalization mean
  normalize_std: [0.229, 0.224, 0.225]   # ImageNet normalization std
  
  # Quality Assessment Thresholds
  min_face_size: 50             # Minimum face size in pixels
  blur_threshold: 100.0         # Laplacian blur threshold
  illumination_threshold: 50.0  # Illumination quality threshold
  
  # Data Integrity
  check_duplicates: true        # Enable duplicate detection
  hash_algorithm: "phash"       # Options: phash, dhash, ahash
  duplicate_threshold: 0.9      # Similarity threshold for duplicates

# Evaluation Configuration
evaluation:
  similarity_threshold: 0.5     # Default similarity threshold
  distance_metric: "cosine"     # Options: cosine, euclidean, manhattan
  
  # Threshold Analysis
  threshold_range: [0.1, 0.9]   # Range for threshold analysis
  threshold_steps: 9            # Number of threshold steps
  
  # Visualization Options
  plot_roc: true               # Generate ROC curves
  plot_precision_recall: true  # Generate PR curves
  plot_similarity_distribution: true  # Generate similarity distributions
  plot_confusion_matrix: true  # Generate confusion matrices
  
  # Statistical Analysis
  confidence_interval: 0.95    # Confidence interval for metrics
  bootstrap_samples: 1000      # Bootstrap samples for CI estimation

# Hardware Configuration
hardware:
  device: "auto"               # Options: auto, cpu, cuda, cuda:0
  num_workers: 4               # Number of data loader workers
  pin_memory: true             # Pin memory for faster GPU transfer
  mixed_precision: true        # Enable mixed precision training

# Logging Configuration
logging:
  level: "INFO"                # Options: DEBUG, INFO, WARNING, ERROR
  log_to_file: true           # Save logs to file
  log_to_tensorboard: true    # Log to TensorBoard
  log_to_wandb: false         # Log to Weights & Biases
  
  # Checkpoint Configuration
  save_best_only: true        # Save only best model
  save_frequency: 5           # Save checkpoint every N epochs
  max_checkpoints: 3          # Maximum number of checkpoints to keep

# Report Configuration
report:
  format: "pdf"               # Options: pdf, html, markdown
  template: "professional"    # Options: professional, academic, minimal
  include_code: false         # Include code snippets in report
  include_raw_data: false     # Include raw evaluation data
  
  # Report Sections
  sections:
    - "executive_summary"
    - "dataset_description"
    - "baseline_performance"
    - "methodology"
    - "results"
    - "data_integrity"
    - "conclusions"
    - "technical_appendix"

# Paths Configuration
paths:
  data_path: null              # Path to dataset (set via CLI)
  output_dir: "outputs"        # Main output directory
  checkpoint_dir: "outputs/checkpoints"  # Model checkpoints
  logs_dir: "outputs/logs"     # Log files
  reports_dir: "reports"       # Generated reports
  figures_dir: "reports/figures"  # Generated figures

# Reproducibility Configuration
reproducibility:
  seed: 42                     # Random seed for reproducibility
  deterministic: true          # Use deterministic algorithms
  benchmark: false             # Enable cudNN benchmarking
  
# Security Configuration
security:
  hash_verification: true      # Verify data integrity with hashes
  strict_split_validation: true  # Enforce strict train/test separation
  audit_trail: true           # Maintain audit trail of operations